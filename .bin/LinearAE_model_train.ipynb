{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import trainHelper\n",
    "import utils\n",
    "from mds.lmds import landmarkMDS\n",
    "from mds.cmds import classicalMDS\n",
    "from mds.fastmap import fastmap\n",
    "import numpy\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import lossFunction as lossF\n",
    "from model.AutoEncoder import AutoEncoder\n",
    "from model.DynParam import DynParam\n",
    "from model.Linear import Linear\n",
    "from model.VAE import VAE\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload\n",
    "reload(sys.modules['utils']);\n",
    "reload(sys.modules['trainHelper']);\n",
    "reload(sys.modules['lossFunction']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.DoubleTensor')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_space = (1000000, 100)\n",
    "ss, N, d = 1000, 15, 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    euclidean_data1 = utils.load_variable('data/euclidean_data1.pkl')\n",
    "    euclidean_data2 = utils.load_variable('data/euclidean_data2.pkl')\n",
    "    \n",
    "    rand_data1 = utils.load_variable('data/rand_data.pkl')\n",
    "    rand_data2 = utils.load_variable('data/rand_data.pkl')\n",
    "    \n",
    "    if euclidean_data.size() != (ss, 1, N, N):\n",
    "        print(\"Updated data for requirement !\")\n",
    "        raise Exception(\"Previous data not match requirement !\")\n",
    "\n",
    "except:\n",
    "    euclidean_data1 = utils.generate_euclidean_DM(\n",
    "        N=N, d=d,\n",
    "        sample_size=ss,\n",
    "        sample_space=sample_space, isInt=True)\n",
    "\n",
    "    euclidean_data2 = utils.generate_euclidean_DM(\n",
    "        N=N, d=d,\n",
    "        sample_size=ss,\n",
    "        sample_space=sample_space, isInt=True)\n",
    "\n",
    "    rand_data1 = utils.generate_rand_DM(\n",
    "        N=N,\n",
    "        sample_size=ss,\n",
    "        sample_space=sample_space, isInt=True)\n",
    "\n",
    "    rand_data2 = utils.generate_rand_DM(\n",
    "        N=N,\n",
    "        sample_size=ss,\n",
    "        sample_space=sample_space, isInt=True)\n",
    "\n",
    "    utils.dump_variable(euclidean_data1, 'data/euclidean_data1.pkl')\n",
    "    utils.dump_variable(euclidean_data2, 'data/euclidean_data2.pkl')\n",
    "\n",
    "    utils.dump_variable(rand_data1, 'data/rand_data1.pkl')\n",
    "    utils.dump_variable(rand_data2, 'data/rand_data2.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.stack([\n",
    "            euclidean_data1,\n",
    "            euclidean_data2,\n",
    "            # rand_data1,\n",
    "            # rand_data2,\n",
    "        ]).view(ss * 2, 1, N, N)\n",
    "\n",
    "data = torch.tensor(utils.vectorize_distance_from_DM(data).data, requires_grad=True)\n",
    "# data = torch.tensor(data.view(ss * 2, 1, N * N).data, requires_grad=True)\n",
    "\n",
    "# data = torch.tensor(euclidean_data.view(ss, 1, N * N).data, requires_grad=True)\n",
    "\n",
    "batch = 32\n",
    "dlr = DataLoader(data, batch_size=batch, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = 200\n",
    "test_data = utils.generate_rand_DM(\n",
    "                N=N,\n",
    "                sample_size=test_batch, \n",
    "                sample_space=sample_space, isInt=True, \n",
    "                v_size=2, \n",
    "                transform_func=lambda x: x[0] ** 2 + x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Test Result:  tensor(3.5483, grad_fn=<MeanBackward1>)\n"
    }
   ],
   "source": [
    "def test_model():\n",
    "\n",
    "    t_data = torch.tensor(utils.vectorize_distance_from_DM(test_data).data, requires_grad=True)\n",
    "    \n",
    "    model_rs = helper.model(t_data)\n",
    "    \n",
    "    model_dm = torch.stack(\n",
    "        [utils.unvectorize_distance(rs, N).view(1, N, N) for rs in model_rs])\n",
    "\n",
    "    return torch.mean((model_dm - d) ** 2)\n",
    "\n",
    "print(\"Test Result: \", test_model())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 \t| Mean loss: 0.05966806314385117\n100 \t| Mean loss: 0.048000652947386147\n200 \t| Mean loss: 0.04756927491769634\nTime used for the training:  1960.020983 s\nTest Result:  tensor(3.5022, grad_fn=<MeanBackward1>)\n0 \t| Mean loss: 0.05945083094780311\n100 \t| Mean loss: 0.04926439288786694\n200 \t| Mean loss: 0.04872649582968837\nTime used for the training:  2005.70552 s\nTest Result:  tensor(3.3713, grad_fn=<MeanBackward1>)\n0 \t| Mean loss: 0.06009331275626099\n100 \t| Mean loss: 0.05619122153769714\n200 \t| Mean loss: 0.056173837739133724\nTime used for the training:  2211.547043 s\nTest Result:  tensor(3.0492, grad_fn=<MeanBackward1>)\n"
    }
   ],
   "source": [
    "for i in [32, 64, 128, 256]:\n",
    "\n",
    "    model_id = \"LinearAE_with_two_\" + str(i) + \"_layers_distance\"\n",
    "\n",
    "    in_dim = data[0].size()[-1]\n",
    "    out_dim = N * 2\n",
    "\n",
    "    model = AutoEncoder([in_dim, i, i, out_dim], final_activation=nn.Sigmoid)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "    lossFun = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    helper = trainHelper.TrainHelper(\n",
    "        id=model_id,\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        lossFun=lossFun,\n",
    "        lr_factor=0.1)\n",
    "\n",
    "\n",
    "    EPOCH = 300\n",
    "    print_on_each = 100\n",
    "\n",
    "    time_used = utils.time_measure(helper.train, \n",
    "                        [dlr, EPOCH, print_on_each])[1]\n",
    "\n",
    "    print(\"Time used for the training: \", time_used, \"s\")\n",
    "\n",
    "    helper.backup()\n",
    "    \n",
    "    print(\"Test Result: \", test_model())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 200\n",
    "print_on_each = 10\n",
    "\n",
    "time_used = utils.time_measure(helper.train, \n",
    "                    [dlr, EPOCH, print_on_each])[1]\n",
    "\n",
    "print(\"Time used for the training: \", time_used, \"s\")\n",
    "\n",
    "helper.backup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.merge_local_record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper.plot(['loss_mean', 'loss_max', 'loss_min'], value_label='loss')\n",
    "helper.plot(['train_time'], value_label='train_time')\n",
    "helper.plot(['lr'], value_label='lr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cmds_loss: \t tensor(71.2871) | 200 success\nfastmap_loss: \t tensor(nan) | 200 success\nmodel_loss: \t tensor(94.6814) | 200 success\nrecon_loss: \t tensor(nan) | 0 success\n"
    }
   ],
   "source": [
    "\n",
    "cmds_loss, fastmap_loss, model_loss = [], [], []\n",
    "recon_loss = []\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for d in test_data:\n",
    "\n",
    "        d1 = numpy.array(d[0].data)\n",
    "\n",
    "        cmds_rs = classicalMDS(d1, 2)\n",
    "        cmds_rs = torch.tensor(cmds_rs)\n",
    "        cmds_dm, _ = utils.get_distance_matrix(cmds_rs)\n",
    "        cmds_loss.append(torch.sum((cmds_dm - d)** 2))\n",
    "\n",
    "        fastmap_rs = fastmap(d1, 2)\n",
    "        fastmap_rs = torch.tensor(fastmap_rs)\n",
    "        fastmap_dm, _ = utils.get_distance_matrix(fastmap_rs)\n",
    "        fastmap_loss.append(torch.sum((fastmap_dm - d)** 2))\n",
    "\n",
    "        d2 = utils.vectorize_distance_from_DM(d)\n",
    "        model_rs = helper.model.encode(d2).view(1, N, 2)\n",
    "        # model_dm = utils.unvectorize_distance(model_rs, N).view(1, N, N) # utils.get_distance_matrix(model_rs)\n",
    "\n",
    "        model_dm, _ = utils.get_distance_matrix(model_rs)\n",
    "        model_loss.append(torch.sum((model_dm - d) ** 2))\n",
    "\n",
    "        try:\n",
    "            recon_dm = helper.model(d2)\n",
    "            recon_dm = utils.unvectorize_distance(model_rs, N).view(1, N, N)\n",
    "\n",
    "            d3 = numpy.array(recon_dm[0].data)\n",
    "\n",
    "            recon_rs = classicalMDS(d3, 2)\n",
    "            recon_rs = torch.tensor(recon_rs)\n",
    "            recon_dm, _ = utils.get_distance_matrix(recon_rs)\n",
    "            recon_loss.append(torch.sum((recon_dm - d)** 2))\n",
    "        except Exception as e: \n",
    "            pass # print(str(e))\n",
    "\n",
    "    print(\"cmds_loss: \\t\", torch.tensor(cmds_loss).mean(), \"|\" , len(cmds_loss), \"success\")    \n",
    "    print(\"fastmap_loss: \\t\", torch.tensor(fastmap_loss).mean(), \"|\" , len(fastmap_loss), \"success\")    \n",
    "    print(\"model_loss: \\t\", torch.tensor(model_loss).mean(), \"|\" , len(model_loss), \"success\")    \n",
    "    print(\"recon_loss: \\t\", torch.tensor(recon_loss).mean(), \"|\" , len(recon_loss), \"success\")    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([[[0.0000, 0.4378, 0.2877, 0.4055, 0.2831, 0.0761, 0.4351, 0.0663,\n           0.1717, 0.3291, 0.7714, 0.1441, 0.0653, 0.0559, 0.1177],\n          [0.4378, 0.0000, 0.1436, 0.0308, 0.0292, 0.4154, 0.2548, 0.2131,\n           0.1566, 0.8453, 0.3693, 0.1154, 0.1806, 0.2552, 0.1227],\n          [0.2877, 0.1436, 0.0000, 0.2569, 0.1723, 0.1352, 0.0259, 0.2429,\n           0.3019, 0.3184, 0.1280, 0.0352, 0.0914, 0.2792, 0.0542],\n          [0.4055, 0.0308, 0.2569, 0.0000, 0.0131, 0.4799, 0.4243, 0.1565,\n           0.0780, 1.0000, 0.6024, 0.1644, 0.1976, 0.1884, 0.1565],\n          [0.2831, 0.0292, 0.1723, 0.0131, 0.0000, 0.3342, 0.3226, 0.0929,\n           0.0505, 0.7877, 0.5118, 0.0868, 0.1090, 0.1202, 0.0795],\n          [0.0761, 0.4154, 0.1352, 0.4799, 0.3342, 0.0000, 0.1943, 0.1808,\n           0.3209, 0.1109, 0.4307, 0.0929, 0.0642, 0.1865, 0.0901],\n          [0.4351, 0.2548, 0.0259, 0.4243, 0.3226, 0.1943, 0.0000, 0.4208,\n           0.5046, 0.2880, 0.0481, 0.1186, 0.2010, 0.4653, 0.1508],\n          [0.0663, 0.2131, 0.2429, 0.1565, 0.0929, 0.1808, 0.4208, 0.0000,\n           0.0249, 0.5744, 0.7213, 0.0932, 0.0451, 0.0019, 0.0679],\n          [0.1717, 0.1566, 0.3019, 0.0780, 0.0505, 0.3209, 0.5046, 0.0249,\n           0.0000, 0.8079, 0.7922, 0.1404, 0.1062, 0.0327, 0.1138],\n          [0.3291, 0.8453, 0.3184, 1.0000, 0.7877, 0.1109, 0.2880, 0.5744,\n           0.8079, 0.0000, 0.4830, 0.3541, 0.3353, 0.5811, 0.3674],\n          [0.7714, 0.3693, 0.1280, 0.6024, 0.5118, 0.4307, 0.0481, 0.7213,\n           0.7922, 0.4830, 0.0000, 0.2969, 0.4339, 0.7845, 0.3483],\n          [0.1441, 0.1154, 0.0352, 0.1644, 0.0868, 0.0929, 0.1186, 0.0932,\n           0.1404, 0.3541, 0.2969, 0.0000, 0.0159, 0.1162, 0.0021],\n          [0.0653, 0.1806, 0.0914, 0.1976, 0.1090, 0.0642, 0.2010, 0.0451,\n           0.1062, 0.3353, 0.4339, 0.0159, 0.0000, 0.0570, 0.0076],\n          [0.0559, 0.2552, 0.2792, 0.1884, 0.1202, 0.1865, 0.4653, 0.0019,\n           0.0327, 0.5811, 0.7845, 0.1162, 0.0570, 0.0000, 0.0874],\n          [0.1177, 0.1227, 0.0542, 0.1565, 0.0795, 0.0901, 0.1508, 0.0679,\n           0.1138, 0.3674, 0.3483, 0.0021, 0.0076, 0.0874, 0.0000]]]),\n tensor([[[0.2830]]]))"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "model_dm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}