{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload\n",
    "\n",
    "try:\n",
    "    reload(sys.modules['utils']);\n",
    "    reload(sys.modules['mds.cmds']);\n",
    "    reload(sys.modules['mds.lmds']);\n",
    "    reload(sys.modules['trainHelper']);\n",
    "    reload(sys.modules['lossFunction']);\n",
    "except:\n",
    "    pass\n",
    "\n",
    "import trainHelper\n",
    "import utils\n",
    "from mds.lmds import landmarkMDS\n",
    "from mds.cmds import classicalMDS\n",
    "from mds.fastmap import fastmap\n",
    "import numpy\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch import nn, Tensor\n",
    "import lossFunction as lossF\n",
    "from model.AutoEncoder import AutoEncoder\n",
    "from model.Linear import Linear\n",
    "import model.RNN as rnn\n",
    "import os.path\n",
    "import glob\n",
    "import dataSource\n",
    "\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_space = (1000, 1)\n",
    "ss, N, d = 3200, 10, 2\n",
    "\n",
    "test_batch = 1000\n",
    "test_data = dataSource.generate_rand_DM(\n",
    "                N=N,\n",
    "                sample_size=test_batch, \n",
    "                sample_space=sample_space, isInt=True)\n",
    "\n",
    "test_data = dataSource.generate_euclidean_DM(\n",
    "                N=N, d=2,\n",
    "                sample_size=test_batch, \n",
    "                sample_space=sample_space, isInt=True)\n",
    "\n",
    "test_data = test_data.view(test_batch, 1, N, N)\n",
    "test_data = utils.minmax_norm(test_data, dmin=0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "cmds_loss: \t tensor(1.9503e-31) | 1000 success\nlmds_loss: \t tensor(0.0292) | 1000 success\nfastmap_loss: \t tensor(0.0448) | 1000 success\n"
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "cmds_loss, fastmap_loss, lmds_loss = [], [], []\n",
    "\n",
    "test_data = utils.load_variable('data\\euclidean.dat')\n",
    "test_data = utils.minmax_norm(test_data, dmin=0)[0]\n",
    "\n",
    "for d in test_data:\n",
    "\n",
    "    d1 = numpy.array(d[0].data) ** 2\n",
    "\n",
    "    cmds_rs = classicalMDS(d1, 2)\n",
    "    cmds_rs = torch.tensor(cmds_rs)\n",
    "    cmds_dm = utils.get_distance_matrix(cmds_rs) ** 0.5 \n",
    "    cmds_dm = utils.minmax_norm(cmds_dm, dmin=0)[0]\n",
    "    \n",
    "    cmds_loss.append(torch.mean((cmds_dm - d)** 2))\n",
    "\n",
    "    lmds_rs = landmarkMDS(d1, L=5, D=2)\n",
    "    lmds_rs = torch.tensor(lmds_rs)\n",
    "    lmds_dm = utils.get_distance_matrix(lmds_rs) ** 0.5\n",
    "    lmds_dm = utils.minmax_norm(lmds_dm, dmin=0)[0]\n",
    "\n",
    "    lmds_loss.append(torch.mean((lmds_dm - d)** 2))\n",
    "\n",
    "    fastmap_rs = fastmap(d1, 2)\n",
    "    fastmap_rs = torch.tensor(fastmap_rs)\n",
    "    fastmap_dm = utils.get_distance_matrix(fastmap_rs) ** 0.5\n",
    "    fastmap_dm = utils.minmax_norm(fastmap_dm, dmin=0)[0]\n",
    "\n",
    "    fastmap_loss.append(torch.mean((fastmap_dm - d)** 2))\n",
    "\n",
    "\n",
    "print(\"cmds_loss: \\t\", \n",
    "        torch.tensor(cmds_loss).mean(), \"|\" , \n",
    "        len(cmds_loss), \"success\")\n",
    "\n",
    "print(\"lmds_loss: \\t\", \n",
    "        torch.tensor(lmds_loss).mean(), \"|\" , \n",
    "        len(lmds_loss), \"success\")\n",
    "\n",
    "print(\"fastmap_loss: \\t\", \n",
    "        torch.tensor(fastmap_loss).mean(), \"|\" , \n",
    "        len(fastmap_loss), \"success\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor(6.3726e-30)"
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "max(cmds_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "backup\\Coord_Linear_1_64_D_MSE_500.model    \t\t\t| tensor(0.0639)\nbackup\\Coord_Linear_1_64_D_MSE_700.model    \t\t\t| tensor(0.0639)\nbackup\\Coord_Linear_1_64_D_MSE_600.model    \t\t\t| tensor(0.0639)\nbackup\\Coord_Linear_1_64_D_MSE_400.model    \t\t\t| tensor(0.0642)\nbackup\\Coord_Linear_1_64_D_MSE_200.model    \t\t\t| tensor(0.0646)\nbackup\\Coord_Linear_1_64_D_MSE_300.model    \t\t\t| tensor(0.0646)\nbackup\\Coord_Linear_2_80_D_MSE_200.model    \t\t\t| tensor(0.0648)\nbackup\\Coord_Linear_2_64_D_MSE_400.model    \t\t\t| tensor(0.0648)\nbackup\\Coord_Linear_2_64_D_MSE_300.model    \t\t\t| tensor(0.0649)\nbackup\\Coord_Linear_2_64_D_MSE_500.model    \t\t\t| tensor(0.0650)\nbackup\\Coord_Linear_2_64_D_MSE_600.model    \t\t\t| tensor(0.0650)\nbackup\\Coord_Linear_2_64_D_MSE_700.model    \t\t\t| tensor(0.0650)\nbackup\\Coord_Linear_1_80_D_MSE_300.model    \t\t\t| tensor(0.0651)\nbackup\\Coord_Linear_1_80_D_MSE_600.model    \t\t\t| tensor(0.0651)\nbackup\\Coord_Linear_1_80_D_MSE_500.model    \t\t\t| tensor(0.0651)\nbackup\\Coord_Linear_2_80_D_MSE_300.model    \t\t\t| tensor(0.0652)\nbackup\\Coord_Linear_1_80_D_MSE_400.model    \t\t\t| tensor(0.0652)\nbackup\\Coord_Linear_1_80_D_MSE_200.model    \t\t\t| tensor(0.0652)\nbackup\\Coord_Linear_2_64_D_MSE_200.model    \t\t\t| tensor(0.0652)\nbackup\\Coord_Linear_1_80_D_MSE_100.model    \t\t\t| tensor(0.0657)\nbackup\\Coord_Linear_2_80_D_MSE_400.model    \t\t\t| tensor(0.0657)\nbackup\\Coord_Linear_2_80_D_MSE_500.model    \t\t\t| tensor(0.0659)\nbackup\\Coord_Linear_2_32_D_MSE_600.model    \t\t\t| tensor(0.0659)\nbackup\\Coord_Linear_2_32_D_MSE_500.model    \t\t\t| tensor(0.0659)\nbackup\\Coord_Linear_2_32_D_MSE_400.model    \t\t\t| tensor(0.0659)\nbackup\\Coord_Linear_2_48_D_MSE_400.model    \t\t\t| tensor(0.0659)\nbackup\\Coord_Linear_2_48_D_MSE_500.model    \t\t\t| tensor(0.0659)\nbackup\\Coord_Linear_2_48_D_MSE_600.model    \t\t\t| tensor(0.0659)\nbackup\\Coord_Linear_2_48_D_MSE_700.model    \t\t\t| tensor(0.0659)\nbackup\\Coord_Linear_2_80_D_MSE_700.model    \t\t\t| tensor(0.0660)\nbackup\\Coord_Linear_2_80_D_MSE_800.model    \t\t\t| tensor(0.0660)\nbackup\\Coord_Linear_2_80_D_MSE_600.model    \t\t\t| tensor(0.0660)\nbackup\\Coord_Linear_2_64_D_MSE_100.model    \t\t\t| tensor(0.0661)\nbackup\\Coord_Linear_2_48_D_MSE_300.model    \t\t\t| tensor(0.0662)\nbackup\\Coord_Linear_1_64_D_MSE_100.model    \t\t\t| tensor(0.0665)\nbackup\\Coord_Linear_2_32_D_MSE_300.model    \t\t\t| tensor(0.0667)\nbackup\\Coord_Linear_2_48_D_MSE_200.model    \t\t\t| tensor(0.0667)\nbackup\\Coord_Linear_2_80_D_MSE_100.model    \t\t\t| tensor(0.0667)\nbackup\\Coord_Linear_3_80_D_MSE_100.model    \t\t\t| tensor(0.0667)\nbackup\\Coord_Linear_3_80_D_MSE_200.model    \t\t\t| tensor(0.0672)\nbackup\\Coord_Linear_3_32_D_MSE_1000.model    \t\t\t| tensor(0.0673)\nbackup\\Coord_Linear_3_32_D_MSE_900.model    \t\t\t| tensor(0.0673)\nbackup\\Coord_Linear_3_32_D_MSE_800.model    \t\t\t| tensor(0.0673)\nbackup\\Coord_Linear_1_48_D_MSE_400.model    \t\t\t| tensor(0.0673)\nbackup\\Coord_Linear_1_48_D_MSE_300.model    \t\t\t| tensor(0.0673)\nbackup\\Coord_Linear_1_48_D_MSE_200.model    \t\t\t| tensor(0.0673)\nbackup\\Coord_Linear_3_32_D_MSE_700.model    \t\t\t| tensor(0.0677)\nbackup\\Coord_Linear_1_48_D_MSE_100.model    \t\t\t| tensor(0.0681)\nbackup\\Coord_Linear_2_32_D_MSE_200.model    \t\t\t| tensor(0.0682)\nbackup\\Coord_Linear_3_48_D_MSE_500.model    \t\t\t| tensor(0.0683)\nbackup\\Coord_Linear_3_48_D_MSE_800.model    \t\t\t| tensor(0.0683)\nbackup\\Coord_Linear_3_48_D_MSE_700.model    \t\t\t| tensor(0.0683)\nbackup\\Coord_Linear_3_48_D_MSE_600.model    \t\t\t| tensor(0.0683)\nbackup\\Coord_Linear_3_80_D_MSE_300.model    \t\t\t| tensor(0.0684)\nbackup\\Coord_Linear_3_32_D_MSE_600.model    \t\t\t| tensor(0.0685)\nbackup\\Coord_Linear_1_32_D_MSE_500.model    \t\t\t| tensor(0.0687)\nbackup\\Coord_Linear_1_32_D_MSE_400.model    \t\t\t| tensor(0.0687)\nbackup\\Coord_Linear_0_64_D_MSE_400.model    \t\t\t| tensor(0.0688)\nbackup\\Coord_Linear_0_64_D_MSE_300.model    \t\t\t| tensor(0.0688)\nbackup\\Coord_Linear_0_64_D_MSE_200.model    \t\t\t| tensor(0.0688)\nbackup\\Coord_Linear_2_48_D_MSE_100.model    \t\t\t| tensor(0.0689)\nbackup\\Coord_Linear_3_48_D_MSE_400.model    \t\t\t| tensor(0.0690)\nbackup\\Coord_Linear_1_32_D_MSE_300.model    \t\t\t| tensor(0.0691)\nbackup\\Coord_Linear_0_64_D_MSE_100.model    \t\t\t| tensor(0.0692)\nbackup\\Coord_Linear_3_32_D_MSE_500.model    \t\t\t| tensor(0.0692)\nbackup\\Coord_Linear_0_80_D_MSE_200.model    \t\t\t| tensor(0.0693)\nbackup\\Coord_Linear_0_80_D_MSE_300.model    \t\t\t| tensor(0.0693)\nbackup\\Coord_Linear_3_48_D_MSE_300.model    \t\t\t| tensor(0.0693)\nbackup\\Coord_Linear_0_48_D_MSE_100.model    \t\t\t| tensor(0.0693)\nbackup\\Coord_Linear_0_48_D_MSE_200.model    \t\t\t| tensor(0.0693)\nbackup\\Coord_Linear_0_48_D_MSE_300.model    \t\t\t| tensor(0.0693)\nbackup\\Coord_Linear_0_32_D_MSE_200.model    \t\t\t| tensor(0.0694)\nbackup\\Coord_Linear_0_32_D_MSE_300.model    \t\t\t| tensor(0.0694)\nbackup\\Coord_Linear_0_80_D_MSE_100.model    \t\t\t| tensor(0.0694)\nbackup\\Coord_Linear_0_16_D_MSE_200.model    \t\t\t| tensor(0.0694)\nbackup\\Coord_Linear_0_16_D_MSE_300.model    \t\t\t| tensor(0.0694)\nbackup\\Coord_Linear_0_16_D_MSE_400.model    \t\t\t| tensor(0.0694)\nbackup\\Coord_Linear_0_32_D_MSE_100.model    \t\t\t| tensor(0.0697)\nbackup\\Coord_Linear_0_16_D_MSE_100.model    \t\t\t| tensor(0.0698)\nbackup\\Coord_Linear_3_80_D_MSE_400.model    \t\t\t| tensor(0.0698)\nbackup\\Coord_Linear_1_32_D_MSE_200.model    \t\t\t| tensor(0.0699)\nbackup\\Coord_Linear_3_48_D_MSE_200.model    \t\t\t| tensor(0.0704)\nbackup\\Coord_Linear_3_80_D_MSE_500.model    \t\t\t| tensor(0.0705)\nbackup\\Coord_Linear_3_64_D_MSE_400.model    \t\t\t| tensor(0.0706)\nbackup\\Coord_Linear_1_32_D_MSE_100.model    \t\t\t| tensor(0.0706)\nbackup\\Coord_Linear_3_64_D_MSE_300.model    \t\t\t| tensor(0.0708)\nbackup\\Coord_Linear_2_32_D_MSE_100.model    \t\t\t| tensor(0.0709)\nbackup\\Coord_Linear_3_64_D_MSE_500.model    \t\t\t| tensor(0.0709)\nbackup\\Coord_Linear_3_64_D_MSE_600.model    \t\t\t| tensor(0.0710)\nbackup\\Coord_Linear_3_64_D_MSE_700.model    \t\t\t| tensor(0.0710)\nbackup\\Coord_Linear_3_80_D_MSE_600.model    \t\t\t| tensor(0.0712)\nbackup\\Coord_Linear_1_16_D_MSE_400.model    \t\t\t| tensor(0.0712)\nbackup\\Coord_Linear_1_16_D_MSE_300.model    \t\t\t| tensor(0.0712)\nbackup\\Coord_Linear_1_16_D_MSE_200.model    \t\t\t| tensor(0.0712)\nbackup\\Coord_Linear_1_16_D_MSE_100.model    \t\t\t| tensor(0.0713)\nbackup\\Coord_Linear_3_64_D_MSE_200.model    \t\t\t| tensor(0.0714)\nbackup\\Coord_Linear_3_80_D_MSE_700.model    \t\t\t| tensor(0.0714)\nbackup\\Coord_Linear_3_80_D_MSE_800.model    \t\t\t| tensor(0.0714)\nbackup\\Coord_Linear_3_80_D_MSE_900.model    \t\t\t| tensor(0.0714)\nbackup\\Coord_Linear_3_32_D_MSE_400.model    \t\t\t| tensor(0.0720)\nbackup\\Coord_Linear_3_48_D_MSE_100.model    \t\t\t| tensor(0.0729)\nbackup\\Coord_Linear_3_32_D_MSE_300.model    \t\t\t| tensor(0.0740)\nbackup\\Coord_Linear_3_64_D_MSE_100.model    \t\t\t| tensor(0.0741)\nbackup\\Coord_Linear_2_16_D_MSE_300.model    \t\t\t| tensor(0.0749)\nbackup\\Coord_Linear_2_16_D_MSE_400.model    \t\t\t| tensor(0.0749)\nbackup\\Coord_Linear_2_16_D_MSE_500.model    \t\t\t| tensor(0.0749)\nbackup\\Coord_Linear_2_16_D_MSE_200.model    \t\t\t| tensor(0.0757)\nbackup\\Coord_Linear_3_32_D_MSE_200.model    \t\t\t| tensor(0.0782)\nbackup\\Coord_Linear_4_32_D_MSE_400.model    \t\t\t| tensor(0.0797)\nbackup\\Coord_Linear_4_32_D_MSE_700.model    \t\t\t| tensor(0.0800)\nbackup\\Coord_Linear_4_32_D_MSE_600.model    \t\t\t| tensor(0.0800)\nbackup\\Coord_Linear_4_32_D_MSE_500.model    \t\t\t| tensor(0.0800)\nbackup\\Coord_Linear_4_32_D_MSE_300.model    \t\t\t| tensor(0.0806)\nbackup\\Coord_Linear_4_80_D_MSE_200.model    \t\t\t| tensor(0.0814)\nbackup\\Coord_Linear_4_32_D_MSE_200.model    \t\t\t| tensor(0.0822)\nbackup\\Coord_Linear_4_48_D_MSE_200.model    \t\t\t| tensor(0.0823)\nbackup\\Coord_Linear_4_64_D_MSE_200.model    \t\t\t| tensor(0.0824)\nbackup\\Coord_Linear_2_16_D_MSE_100.model    \t\t\t| tensor(0.0828)\nbackup\\Coord_Linear_4_48_D_MSE_300.model    \t\t\t| tensor(0.0830)\nbackup\\Coord_Linear_4_48_D_MSE_400.model    \t\t\t| tensor(0.0833)\nbackup\\Coord_Linear_4_80_D_MSE_300.model    \t\t\t| tensor(0.0836)\nbackup\\Coord_Linear_4_64_D_MSE_300.model    \t\t\t| tensor(0.0838)\nbackup\\Coord_Linear_4_80_D_MSE_100.model    \t\t\t| tensor(0.0840)\nbackup\\Coord_Linear_4_64_D_MSE_400.model    \t\t\t| tensor(0.0843)\nbackup\\Coord_Linear_4_48_D_MSE_500.model    \t\t\t| tensor(0.0843)\nbackup\\Coord_Linear_4_48_D_MSE_800.model    \t\t\t| tensor(0.0846)\nbackup\\Coord_Linear_4_48_D_MSE_700.model    \t\t\t| tensor(0.0846)\nbackup\\Coord_Linear_4_48_D_MSE_600.model    \t\t\t| tensor(0.0846)\nbackup\\Coord_Linear_4_64_D_MSE_500.model    \t\t\t| tensor(0.0849)\nbackup\\Coord_Linear_4_48_D_MSE_100.model    \t\t\t| tensor(0.0850)\nbackup\\Coord_Linear_4_80_D_MSE_400.model    \t\t\t| tensor(0.0852)\nbackup\\Coord_Linear_4_64_D_MSE_600.model    \t\t\t| tensor(0.0854)\nbackup\\Coord_Linear_4_64_D_MSE_700.model    \t\t\t| tensor(0.0856)\nbackup\\Coord_Linear_4_64_D_MSE_900.model    \t\t\t| tensor(0.0857)\nbackup\\Coord_Linear_4_64_D_MSE_800.model    \t\t\t| tensor(0.0857)\nbackup\\Coord_Linear_4_80_D_MSE_500.model    \t\t\t| tensor(0.0859)\nbackup\\Coord_Linear_4_80_D_MSE_600.model    \t\t\t| tensor(0.0864)\nbackup\\Coord_Linear_4_80_D_MSE_700.model    \t\t\t| tensor(0.0867)\nbackup\\Coord_Linear_4_80_D_MSE_800.model    \t\t\t| tensor(0.0872)\nbackup\\Coord_Linear_4_80_D_MSE_900.model    \t\t\t| tensor(0.0875)\nbackup\\Coord_Linear_5_48_D_MSE_1000.model    \t\t\t| tensor(0.0881)\nbackup\\Coord_Linear_5_48_D_MSE_900.model    \t\t\t| tensor(0.0882)\nbackup\\Coord_Linear_5_48_D_MSE_800.model    \t\t\t| tensor(0.0884)\nbackup\\Coord_Linear_5_48_D_MSE_700.model    \t\t\t| tensor(0.0890)\nbackup\\Coord_Linear_3_32_D_MSE_100.model    \t\t\t| tensor(0.0891)\nbackup\\Coord_Linear_4_64_D_MSE_100.model    \t\t\t| tensor(0.0903)\nbackup\\Coord_Linear_5_48_D_MSE_600.model    \t\t\t| tensor(0.0903)\nbackup\\Coord_Linear_4_32_D_MSE_100.model    \t\t\t| tensor(0.0915)\nbackup\\Coord_Linear_5_48_D_MSE_500.model    \t\t\t| tensor(0.0916)\nbackup\\Coord_Linear_5_48_D_MSE_400.model    \t\t\t| tensor(0.0929)\nbackup\\Coord_Linear_5_48_D_MSE_300.model    \t\t\t| tensor(0.0956)\nbackup\\Coord_Linear_3_16_D_MSE_200.model    \t\t\t| tensor(0.0970)\nbackup\\Coord_Linear_3_16_D_MSE_300.model    \t\t\t| tensor(0.0970)\nbackup\\Coord_Linear_3_16_D_MSE_400.model    \t\t\t| tensor(0.0970)\nbackup\\Coord_Linear_3_16_D_MSE_100.model    \t\t\t| tensor(0.0975)\nbackup\\Coord_Linear_5_48_D_MSE_200.model    \t\t\t| tensor(0.1007)\nbackup\\Coord_Linear_4_16_D_MSE_100.model    \t\t\t| tensor(0.1080)\nbackup\\Coord_Linear_4_16_D_MSE_200.model    \t\t\t| tensor(0.1080)\nbackup\\Coord_Linear_4_16_D_MSE_300.model    \t\t\t| tensor(0.1080)\nbackup\\Coord_Linear_5_16_D_MSE_200.model    \t\t\t| tensor(0.1082)\nbackup\\Coord_Linear_5_16_D_MSE_300.model    \t\t\t| tensor(0.1082)\nbackup\\Coord_Linear_5_16_D_MSE_100.model    \t\t\t| tensor(0.1082)\nbackup\\Coord_Linear_5_48_D_MSE_100.model    \t\t\t| tensor(0.1089)\nbackup\\Coord_Linear_5_32_D_MSE_300.model    \t\t\t| tensor(0.1140)\nbackup\\Coord_Linear_5_32_D_MSE_200.model    \t\t\t| tensor(0.1140)\nbackup\\Coord_Linear_5_32_D_MSE_100.model    \t\t\t| tensor(0.1141)\nbackup\\Coord_Linear_5_64_D_MSE_200.model    \t\t\t| tensor(0.1456)\nbackup\\Coord_Linear_5_64_D_MSE_100.model    \t\t\t| tensor(0.1456)\n"
    }
   ],
   "source": [
    "\n",
    "def linear_test_model(model, preprocess, test_data, target_dm):\n",
    "\n",
    "    t_data = preprocess(test_data)\n",
    "    t_data = utils.minmax_norm(t_data, dmin=0)[0]\n",
    "\n",
    "    model_rs = model(t_data)\n",
    "    model_rs = model_rs.view(model_rs.size()[0], *target_dm)\n",
    "\n",
    "    model_dm = utils.get_distance_matrix(model_rs) ** 0.5\n",
    "    model_dm = utils.minmax_norm(model_dm, dmin=0)[0]\n",
    "\n",
    "    loss = (model_dm - test_data.view_as(model_dm)) ** 2\n",
    "\n",
    "    return torch.mean(loss)\n",
    "    \n",
    "\n",
    "linear_result_score = []\n",
    "\n",
    "all_lrs = []\n",
    "\n",
    "to_loop = set(glob.glob('backup/Coord_Linear*.model'))\n",
    "\n",
    "for filepath in to_loop:\n",
    "    h: trainHelper.TrainHelper = utils.load_variable(filepath)\n",
    "    linear_result_score.append([\n",
    "        filepath, \n",
    "        linear_test_model(h.model, h.preprocess, test_data, (N, 2))\n",
    "        ])\n",
    "\n",
    "linear_result_score = sorted(linear_result_score, key=lambda x: x[1])\n",
    "\n",
    "for rss in linear_result_score[:]:\n",
    "    print(rss[0], \"   \\t\\t\\t|\", rss[1].data)\n",
    "\n",
    "# all_lrs.append(['matrix_LReLU_900.model', '5', '64', '0.0691536749058093'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rs = numpy.array(all_lrs)\n",
    "\n",
    "for i in [32, 64, 96]:\n",
    "    t = rs[rs[:, 2] == str(i)]\n",
    "    t = t[t[:, 0] == 'distance_LReLU_900.model']\n",
    "\n",
    "    t = t[t[:, 1].argsort()]\n",
    "    \n",
    "    print(t)\n",
    "\n",
    "    plt.ylabel(\"loss\")\n",
    "    plt.xlabel(\"number of layers\")\n",
    "\n",
    "    plt.plot(t[:, 1], t[:, 3].astype('double'), label=str(i))\n",
    "\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_loop = set(glob.glob('backup/Coord*_96_distance_*_900.model')) - set(glob.glob('backup/*eign*.model'))\n",
    "\n",
    "for filepath in sorted(to_loop):\n",
    "    h: trainHelper.TrainHelper = utils.load_variable(filepath)\n",
    "    t = h.records\n",
    "    print(t)\n",
    "    plt.plot(range(900), t['loss_sum'],label=filepath[20])\n",
    "\n",
    "plt.xlabel('SSE')\n",
    "plt.ylabel('Epoch')\n",
    "\n",
    "plt.legend()\n",
    "# plt.xscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "def recon_test_model(model, preprocess, test_data, target_dm):\n",
    "\n",
    "    t_data = preprocess(test_data)\n",
    "    t_data = utils.minmax_norm(t_data)[0]\n",
    "\n",
    "    model_rs = model(t_data ** 2)\n",
    "    model_rs = utils.minmax_norm(model_rs)[0]\n",
    "\n",
    "    model_dm =  utils.unvectorize_distance(model_rs)\n",
    "\n",
    "    score = []\n",
    "\n",
    "    batch = model_dm.size()[0]\n",
    "\n",
    "    for i in range(batch):\n",
    "        dm = model_dm[i]\n",
    "        # t = test_data[i].view_as(dm)\n",
    "\n",
    "        # score.append(torch.mean((dm - t) ** 2))\n",
    "        # continue\n",
    "\n",
    "        rs = classicalMDS(dm.data, 2)\n",
    "        rs = torch.tensor(rs)\n",
    "\n",
    "        rs_dm = utils.get_distance_matrix(rs) ** 0.5\n",
    "        rs_dm = utils.minmax_norm(rs_dm, dmin=0)[0]\n",
    "\n",
    "        loss = (rs_dm - test_data[i].view_as(rs_dm)) ** 2\n",
    "\n",
    "        score.append(torch.mean(loss))\n",
    "\n",
    "    return torch.tensor(score).mean()\n",
    "\n",
    "\n",
    "recon_result_score = []\n",
    "\n",
    "for filepath in glob.iglob('backup/Recon_*900.model'):\n",
    "    h: trainHelper.TrainHelper = utils.load_variable(filepath)\n",
    "    recon_result_score.append([\n",
    "        filepath, \n",
    "        recon_test_model(h.model, h.preprocess, test_data, (N, 2))\n",
    "        ])\n",
    "    \n",
    "recon_result_score = sorted(recon_result_score, key=lambda x: x[1])\n",
    "\n",
    "for rss in recon_result_score[:]:\n",
    "    print(rss[0], \"   \\t\\t\\t|\", rss[1].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lrs_recon = []\n",
    "\n",
    "for rs in recon_result_score:\n",
    "    t = rs[0]\n",
    "    if t[13] == 'L':\n",
    "        all_lrs_recon.append([t[13], t[20], t[22:24], float(rs[1])])\n",
    "    else:\n",
    "        all_lrs_recon.append([t[13], t[16], t[18:20], float(rs[1])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rs = numpy.array(all_lrs_recon)\n",
    "\n",
    "for m in ['A']:\n",
    "    for i in [32, 64, 96]:\n",
    "        t = rs[rs[:, 2] == str(i)]\n",
    "        t = t[t[:, 0] == m]\n",
    "\n",
    "        t = t[t[:, 1].argsort()]\n",
    "        \n",
    "        print(t)\n",
    "\n",
    "        plt.ylabel(\"loss\")\n",
    "        plt.xlabel(\"number of layers\")\n",
    "\n",
    "        plt.plot(t[:, 1], t[:, 3].astype('double'), label=str(i))\n",
    "\n",
    "\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoordsToDMLoss(nn.Module):\n",
    "\n",
    "    def __init__(self, N, d):\n",
    "        super(CoordsToDMLoss, self).__init__()\n",
    "\n",
    "        self.N = N\n",
    "        self.d = d\n",
    "\n",
    "    def forward(self, rs, target_dm):\n",
    "\n",
    "        batch = target_dm.size()[0]\n",
    "\n",
    "        rs = rs.view(batch, self.N, self.d)\n",
    "\n",
    "        model_dm = utils.get_distance_matrix(rs)\n",
    "        model_dm = utils.minmax_norm(model_dm, dmin=0)[0]\n",
    "\n",
    "        target_dm = torch.pow(target_dm, 2)\n",
    "        target_dm = utils.minmax_norm(target_dm, dmin=0)[0]\n",
    "\n",
    "        loss = model_dm - target_dm.view_as(model_dm)\n",
    "        loss = torch.pow(loss, 2)\n",
    "\n",
    "        loss = loss.view(loss.size()[0], 1, -1)\n",
    "        return torch.sum(torch.sum(loss, dim=2) ** 2)\n",
    "\n",
    "\n",
    "def preprocess(x):\n",
    "    return x.clone().detach().requires_grad_(True)\n",
    "\n",
    "\n",
    "def DM_distance(x):\n",
    "    x = utils.vectorize_distance_from_DM(x)\n",
    "    return preprocess(x)\n",
    "\n",
    "\n",
    "class ReconLoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        super(ReconLoss, self).__init__()\n",
    "\n",
    "    def forward(self, rs, target_dm):\n",
    "\n",
    "        model_dm = rs\n",
    "        model_dm = utils.minmax_norm(model_dm, dmin=0)[0]\n",
    "\n",
    "        target_dm = torch.pow(target_dm, 2)\n",
    "        target_dm = utils.minmax_norm(target_dm, dmin=0)[0]\n",
    "\n",
    "        target_dm = utils.vectorize_distance_from_DM(target_dm)\n",
    "\n",
    "        loss = model_dm - target_dm.view_as(model_dm)\n",
    "        loss = torch.pow(loss, 2)\n",
    "\n",
    "        loss = loss.view(loss.size()[0], 1, -1)\n",
    "        return torch.sum(torch.sum(loss, dim=2) ** 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.eignmatrix(d1.view(2, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = utils.load_variable('backup/bk_squre/Linear_SGD_2_32_distance_LReLU_300.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h.records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_check.bad_grad_viz import view_gradient\n",
    "\n",
    "l = utils.get_distance_matrix())\n",
    "view_gradient(torch.sum(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "eps = torch.tensor(1e-8, requires_grad=True)\n",
    "\n",
    "def sammon_loss(result, target):\n",
    "    \n",
    "    result = torch.triu(result)\n",
    "    target = torch.triu(target)\n",
    "    \n",
    "    loss = torch.pow(target - result, 2)\n",
    "\n",
    "    a = torch.div(loss, target + eps)\n",
    "    a = torch.sum(a)\n",
    "\n",
    "    b = torch.sum(target)\n",
    "    \n",
    "    print(a, b)\n",
    "    \n",
    "    return torch.div(a, b)\n",
    "\n",
    "\n",
    "target = torch.tensor([\n",
    "        [0, 1, 2],\n",
    "        [1, 0, 3],\n",
    "        [2, 3, 0.0]\n",
    "    ], requires_grad=True)\n",
    "\n",
    "rs = torch.tensor([\n",
    "        [0, 4, 2],\n",
    "        [4, 0, 3],\n",
    "        [2, 3, 0.0]\n",
    "    ], requires_grad=True)\n",
    "\n",
    "\n",
    "loss = sammon_loss(rs, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.triu(target)\n",
    "a = torch.nonzero(a)\n",
    "print(a)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytriu = torch.triu(target)\n",
    "idx = torch.nonzero(torch.triu(torch.ones(*mytriu.size())).view(-1)).view(-1)\n",
    "vec = mytriu.view(-1)[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradient_check.bad_grad_viz import view_gradient\n",
    "\n",
    "view_gradient(torch.sum(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Linear([3, 16, 16, 1])\n",
    "optim = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "ackward0>)\ntensor([1.1502e-05], grad_fn=<PowBackward0>)\ntensor([0.0008], grad_fn=<PowBackward0>)\ntensor([8.1124e-05], grad_fn=<PowBackward0>)\ntensor([2.9526e-05], grad_fn=<PowBackward0>)\ntensor([1.1923e-05], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([3.4663e-09], grad_fn=<PowBackward0>)\ntensor([3.3728e-05], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([1.7079e-06], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([7.3488e-06], grad_fn=<PowBackward0>)\ntensor([0.0051], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0018], grad_fn=<PowBackward0>)\ntensor([0.0013], grad_fn=<PowBackward0>)\ntensor([0.0021], grad_fn=<PowBackward0>)\ntensor([0.0011], grad_fn=<PowBackward0>)\ntensor([0.0011], grad_fn=<PowBackward0>)\ntensor([5.7970e-05], grad_fn=<PowBackward0>)\ntensor([0.0014], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([0.0011], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([9.2509e-05], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0013], grad_fn=<PowBackward0>)\ntensor([0.0013], grad_fn=<PowBackward0>)\ntensor([0.0049], grad_fn=<PowBackward0>)\ntensor([0.0011], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([4.1239e-05], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([1.6746e-05], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([0.0014], grad_fn=<PowBackward0>)\ntensor([0.0010], grad_fn=<PowBackward0>)\ntensor([0.0022], grad_fn=<PowBackward0>)\ntensor([3.5573e-05], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0008], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0031], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0013], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([5.9350e-05], grad_fn=<PowBackward0>)\ntensor([5.1310e-06], grad_fn=<PowBackward0>)\ntensor([6.9221e-05], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([2.4913e-05], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([0.0020], grad_fn=<PowBackward0>)\ntensor([2.8240e-05], grad_fn=<PowBackward0>)\ntensor([9.7767e-06], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([8.2875e-05], grad_fn=<PowBackward0>)\ntensor([0.0014], grad_fn=<PowBackward0>)\ntensor([0.0009], grad_fn=<PowBackward0>)\ntensor([0.0011], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([2.7324e-05], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([5.9681e-06], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([8.7633e-05], grad_fn=<PowBackward0>)\ntensor([1.5944e-05], grad_fn=<PowBackward0>)\ntensor([1.8353e-05], grad_fn=<PowBackward0>)\ntensor([0.0007], grad_fn=<PowBackward0>)\ntensor([8.2464e-05], grad_fn=<PowBackward0>)\ntensor([0.0033], grad_fn=<PowBackward0>)\ntensor([0.0037], grad_fn=<PowBackward0>)\ntensor([0.0011], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([2.1232e-06], grad_fn=<PowBackward0>)\ntensor([1.9870e-05], grad_fn=<PowBackward0>)\ntensor([0.0009], grad_fn=<PowBackward0>)\ntensor([0.0007], grad_fn=<PowBackward0>)\ntensor([0.0009], grad_fn=<PowBackward0>)\ntensor([0.0008], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([3.6236e-07], grad_fn=<PowBackward0>)\ntensor([0.0028], grad_fn=<PowBackward0>)\ntensor([3.3969e-05], grad_fn=<PowBackward0>)\ntensor([0.0024], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([1.4709e-08], grad_fn=<PowBackward0>)\ntensor([7.3775e-06], grad_fn=<PowBackward0>)\ntensor([6.0263e-05], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([1.3813e-06], grad_fn=<PowBackward0>)\ntensor([8.3760e-06], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0016], grad_fn=<PowBackward0>)\ntensor([3.8942e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0039], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([1.8886e-05], grad_fn=<PowBackward0>)\ntensor([1.2444e-05], grad_fn=<PowBackward0>)\ntensor([0.0008], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([4.0888e-05], grad_fn=<PowBackward0>)\ntensor([1.2796e-06], grad_fn=<PowBackward0>)\ntensor([3.2243e-06], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([2.4977e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([3.8987e-06], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([2.3196e-05], grad_fn=<PowBackward0>)\ntensor([7.9249e-05], grad_fn=<PowBackward0>)\ntensor([0.0008], grad_fn=<PowBackward0>)\ntensor([1.5373e-05], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([1.2075e-07], grad_fn=<PowBackward0>)\ntensor([4.2091e-06], grad_fn=<PowBackward0>)\ntensor([0.0007], grad_fn=<PowBackward0>)\ntensor([1.7403e-05], grad_fn=<PowBackward0>)\ntensor([2.1826e-05], grad_fn=<PowBackward0>)\ntensor([3.4455e-06], grad_fn=<PowBackward0>)\ntensor([0.0025], grad_fn=<PowBackward0>)\ntensor([9.7221e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([1.8496e-05], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([1.0876e-05], grad_fn=<PowBackward0>)\ntensor([8.2841e-05], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([6.7572e-06], grad_fn=<PowBackward0>)\ntensor([9.2832e-05], grad_fn=<PowBackward0>)\ntensor([0.0009], grad_fn=<PowBackward0>)\ntensor([8.4661e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([9.1249e-06], grad_fn=<PowBackward0>)\ntensor([5.1205e-05], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([3.1172e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([1.6936e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([4.7641e-06], grad_fn=<PowBackward0>)\ntensor([7.2678e-06], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([1.7404e-05], grad_fn=<PowBackward0>)\ntensor([3.0441e-05], grad_fn=<PowBackward0>)\ntensor([4.1588e-05], grad_fn=<PowBackward0>)\ntensor([3.0808e-06], grad_fn=<PowBackward0>)\ntensor([2.6680e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([1.4039e-07], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([3.6265e-05], grad_fn=<PowBackward0>)\ntensor([3.1112e-05], grad_fn=<PowBackward0>)\ntensor([4.8530e-05], grad_fn=<PowBackward0>)\ntensor([3.1728e-05], grad_fn=<PowBackward0>)\ntensor([7.1021e-05], grad_fn=<PowBackward0>)\ntensor([1.3458e-05], grad_fn=<PowBackward0>)\ntensor([1.6862e-07], grad_fn=<PowBackward0>)\ntensor([7.7762e-05], grad_fn=<PowBackward0>)\ntensor([0.0014], grad_fn=<PowBackward0>)\ntensor([0.0009], grad_fn=<PowBackward0>)\ntensor([4.4855e-05], grad_fn=<PowBackward0>)\ntensor([1.0208e-06], grad_fn=<PowBackward0>)\ntensor([0.0007], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([2.6789e-05], grad_fn=<PowBackward0>)\ntensor([6.4663e-05], grad_fn=<PowBackward0>)\ntensor([3.0457e-06], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([5.5513e-05], grad_fn=<PowBackward0>)\ntensor([7.8888e-08], grad_fn=<PowBackward0>)\ntensor([8.1183e-05], grad_fn=<PowBackward0>)\ntensor([0.0009], grad_fn=<PowBackward0>)\ntensor([7.4780e-05], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([4.6953e-06], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([1.0674e-05], grad_fn=<PowBackward0>)\ntensor([3.6980e-05], grad_fn=<PowBackward0>)\ntensor([7.9270e-05], grad_fn=<PowBackward0>)\ntensor([2.8356e-05], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0008], grad_fn=<PowBackward0>)\ntensor([0.0010], grad_fn=<PowBackward0>)\ntensor([8.6743e-07], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0010], grad_fn=<PowBackward0>)\ntensor([0.0026], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0012], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([3.8943e-05], grad_fn=<PowBackward0>)\ntensor([3.8112e-05], grad_fn=<PowBackward0>)\ntensor([0.0007], grad_fn=<PowBackward0>)\ntensor([0.0018], grad_fn=<PowBackward0>)\ntensor([0.0010], grad_fn=<PowBackward0>)\ntensor([0.0020], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([7.5265e-05], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([2.4110e-05], grad_fn=<PowBackward0>)\ntensor([7.3315e-07], grad_fn=<PowBackward0>)\ntensor([6.2529e-05], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([1.5325e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0008], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0015], grad_fn=<PowBackward0>)\ntensor([0.0023], grad_fn=<PowBackward0>)\ntensor([7.9667e-05], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0008], grad_fn=<PowBackward0>)\ntensor([0.0020], grad_fn=<PowBackward0>)\ntensor([5.4278e-07], grad_fn=<PowBackward0>)\ntensor([2.9178e-05], grad_fn=<PowBackward0>)\ntensor([1.2594e-06], grad_fn=<PowBackward0>)\ntensor([0.0008], grad_fn=<PowBackward0>)\ntensor([1.1742e-05], grad_fn=<PowBackward0>)\ntensor([2.1338e-06], grad_fn=<PowBackward0>)\ntensor([0.0010], grad_fn=<PowBackward0>)\ntensor([9.2852e-05], grad_fn=<PowBackward0>)\ntensor([2.6612e-05], grad_fn=<PowBackward0>)\ntensor([0.0018], grad_fn=<PowBackward0>)\ntensor([2.5807e-06], grad_fn=<PowBackward0>)\ntensor([4.0631e-07], grad_fn=<PowBackward0>)\ntensor([0.0011], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([8.0009e-05], grad_fn=<PowBackward0>)\ntensor([0.0019], grad_fn=<PowBackward0>)\ntensor([2.8776e-05], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([6.0803e-05], grad_fn=<PowBackward0>)\ntensor([6.6065e-05], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([0.0020], grad_fn=<PowBackward0>)\ntensor([0.0016], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0009], grad_fn=<PowBackward0>)\ntensor([0.0012], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([0.0013], grad_fn=<PowBackward0>)\ntensor([1.7708e-06], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([3.4397e-05], grad_fn=<PowBackward0>)\ntensor([3.3991e-05], grad_fn=<PowBackward0>)\ntensor([2.5726e-06], grad_fn=<PowBackward0>)\ntensor([0.0027], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([0.0013], grad_fn=<PowBackward0>)\ntensor([6.8133e-05], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0019], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([0.0016], grad_fn=<PowBackward0>)\ntensor([9.2373e-06], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([7.2231e-05], grad_fn=<PowBackward0>)\ntensor([5.6330e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0007], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([4.9599e-05], grad_fn=<PowBackward0>)\ntensor([0.0020], grad_fn=<PowBackward0>)\ntensor([1.6331e-05], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([0.0010], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0033], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([6.8349e-05], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([5.0663e-05], grad_fn=<PowBackward0>)\ntensor([2.8967e-05], grad_fn=<PowBackward0>)\ntensor([6.3669e-06], grad_fn=<PowBackward0>)\ntensor([7.9524e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([9.9117e-05], grad_fn=<PowBackward0>)\ntensor([0.0007], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0013], grad_fn=<PowBackward0>)\ntensor([0.0011], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([8.2182e-05], grad_fn=<PowBackward0>)\ntensor([1.4951e-09], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([8.4650e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0020], grad_fn=<PowBackward0>)\ntensor([0.0011], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([2.9915e-06], grad_fn=<PowBackward0>)\ntensor([5.1555e-07], grad_fn=<PowBackward0>)\ntensor([1.5343e-08], grad_fn=<PowBackward0>)\ntensor([4.7097e-05], grad_fn=<PowBackward0>)\ntensor([6.5309e-05], grad_fn=<PowBackward0>)\ntensor([9.2024e-05], grad_fn=<PowBackward0>)\ntensor([2.2635e-08], grad_fn=<PowBackward0>)\ntensor([1.4491e-06], grad_fn=<PowBackward0>)\ntensor([2.6643e-06], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0013], grad_fn=<PowBackward0>)\ntensor([0.0007], grad_fn=<PowBackward0>)\ntensor([5.5496e-08], grad_fn=<PowBackward0>)\ntensor([1.2746e-05], grad_fn=<PowBackward0>)\ntensor([8.4752e-05], grad_fn=<PowBackward0>)\ntensor([7.3326e-05], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0019], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([7.1942e-05], grad_fn=<PowBackward0>)\ntensor([0.0016], grad_fn=<PowBackward0>)\ntensor([0.0010], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([1.3643e-05], grad_fn=<PowBackward0>)\ntensor([2.6285e-05], grad_fn=<PowBackward0>)\ntensor([1.6661e-05], grad_fn=<PowBackward0>)\ntensor([0.0010], grad_fn=<PowBackward0>)\ntensor([9.8201e-05], grad_fn=<PowBackward0>)\ntensor([0.0009], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0009], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([6.7190e-06], grad_fn=<PowBackward0>)\ntensor([1.5229e-05], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([2.7636e-05], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([2.3054e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([2.4272e-05], grad_fn=<PowBackward0>)\ntensor([0.0007], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([2.7202e-06], grad_fn=<PowBackward0>)\ntensor([5.3495e-06], grad_fn=<PowBackward0>)\ntensor([1.6893e-07], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([1.0905e-05], grad_fn=<PowBackward0>)\ntensor([9.4998e-05], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([3.0912e-06], grad_fn=<PowBackward0>)\ntensor([6.5089e-07], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0006], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([5.2105e-06], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([7.4300e-05], grad_fn=<PowBackward0>)\ntensor([6.6894e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([8.6012e-05], grad_fn=<PowBackward0>)\ntensor([8.2938e-05], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([1.2052e-06], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([4.0291e-05], grad_fn=<PowBackward0>)\ntensor([0.0001], grad_fn=<PowBackward0>)\ntensor([0.0035], grad_fn=<PowBackward0>)\ntensor([1.4083e-05], grad_fn=<PowBackward0>)\ntensor([9.6360e-06], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([7.9717e-05], grad_fn=<PowBackward0>)\ntensor([1.7760e-05], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([1.5956e-06], grad_fn=<PowBackward0>)\ntensor([4.8093e-05], grad_fn=<PowBackward0>)\ntensor([2.0473e-05], grad_fn=<PowBackward0>)\ntensor([6.7849e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([7.7154e-05], grad_fn=<PowBackward0>)\ntensor([0.0005], grad_fn=<PowBackward0>)\ntensor([2.2251e-06], grad_fn=<PowBackward0>)\ntensor([0.0007], grad_fn=<PowBackward0>)\ntensor([3.4058e-05], grad_fn=<PowBackward0>)\ntensor([0.0007], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([1.7194e-06], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([8.6600e-06], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([0.0009], grad_fn=<PowBackward0>)\ntensor([3.7557e-06], grad_fn=<PowBackward0>)\ntensor([7.0771e-07], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([7.9935e-05], grad_fn=<PowBackward0>)\ntensor([0.0002], grad_fn=<PowBackward0>)\ntensor([5.3413e-05], grad_fn=<PowBackward0>)\ntensor([1.1426e-05], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([1.3347e-07], grad_fn=<PowBackward0>)\ntensor([0.0003], grad_fn=<PowBackward0>)\ntensor([0.0004], grad_fn=<PowBackward0>)\ntensor([3.8480e-05], grad_fn=<PowBackward0>)\n"
    }
   ],
   "source": [
    "cal = lambda x: x[0] * x[1] + x[2]\n",
    "\n",
    "for i in range(10000):\n",
    "    optim.zero_grad()\n",
    "\n",
    "    x = torch.rand(3)\n",
    "    loss = model(torch.tensor(x.data, requires_grad=True)) - cal(x.data)\n",
    "    loss = torch.pow(loss, 2)\n",
    "\n",
    "    print(loss)\n",
    "    \n",
    "    loss.backward()\n",
    "    optim.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(tensor([0.3054], grad_fn=<AddBackward0>), 0.32)"
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "model(torch.tensor([0.1, 0.2, 0.3])), cal([0.1, 0.2, 0.3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "1.0"
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "round(1.0000002, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}